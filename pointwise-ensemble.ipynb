{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import evaluation_shared_task as evalfun\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG = \"en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE_LIST = [5,10,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = json.load(open(\"data/Train_\"+LANG+\"_new.json\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = json.load(open(\"data/Dev_\"+LANG+\"_new.json\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"text_splited\"] = train[\"text\"].split(\" \")\n",
    "dev[\"text_splited\"] = dev[\"text\"].split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"sentences_list\"] = {}\n",
    "dev[\"sentences_list\"] = {}\n",
    "for WINDOW_SIZE in WINDOW_SIZE_LIST:\n",
    "    PAD = \"<pad>\"\n",
    "    train[\"sentences_list\"][WINDOW_SIZE] = [PAD for i in range(WINDOW_SIZE)]\n",
    "    train[\"sentences_list\"][WINDOW_SIZE].extend([word.lower().replace(\"\\n\",\"\") for word in train[\"text_splited\"]])\n",
    "    train[\"sentences_list\"][WINDOW_SIZE].extend([PAD for i in range(WINDOW_SIZE)])\n",
    "    dev[\"sentences_list\"][WINDOW_SIZE] = [PAD for i in range(WINDOW_SIZE)]\n",
    "    dev[\"sentences_list\"][WINDOW_SIZE].extend([word.lower().replace(\"\\n\",\"\") for word in dev[\"text_splited\"]])\n",
    "    dev[\"sentences_list\"][WINDOW_SIZE].extend([PAD for i in range(WINDOW_SIZE)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_list = glob.glob(\"model-\"+LANG+\"-*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "pos_tag_dict = {}\n",
    "for i, (k, v) in enumerate(nltk.data.load('help/tagsets/upenn_tagset.pickle').items()):\n",
    "    pos_tag_dict[k] = i\n",
    "pos_tag_dict[\"other\"] = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v(word,_w2v_model,_w2v_dim):\n",
    "    try:\n",
    "        word_vector = _w2v_model.wv[word.lower().replace(\"\\n\",\"\")]\n",
    "    except:\n",
    "        word_vector = np.array([0.0 for i in range(_w2v_dim)])\n",
    "    try:\n",
    "        tag = pos_tag_dict[nltk.pos_tag([word])[0][1]]\n",
    "    except:\n",
    "        tag = pos_tag_dict[\"other\"]\n",
    "    pos_vec = np.array([1.0 if i == tag  else 0.0 for i in range(len(pos_tag_dict))])\n",
    "    ##数字記号:0, 全部小文字: 1, 全部大文字: 2, 大文字1+小文字: 3, other:4\n",
    "    class_ul = 0\n",
    "    if word == PAD:\n",
    "        class_ul = 4\n",
    "    elif not word.isalpha():\n",
    "        class_ul = 0\n",
    "    elif word.lower() == word:\n",
    "        class_ul = 1\n",
    "    elif word.upper() == word:\n",
    "        class_ul = 2\n",
    "    elif word[0].upper() == word[0] and word[1:].lower() == word[1:]:\n",
    "        class_ul = 3\n",
    "    else:\n",
    "        class_ul = 4\n",
    "    capital_vec = np.array([1.0 if i == class_ul else 0.0 for i in range(5)])\n",
    "    ###\"\\n\"が含まれているか\n",
    "    if word[-1:] == \"\\n\":\n",
    "        n_vec = np.array([1.0])\n",
    "    else:\n",
    "        n_vec = np.array([0.0])\n",
    "    return np.concatenate([word_vector, pos_vec, capital_vec,n_vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkInput(words_list,_w2v_model,_w2v_dim):\n",
    "    return np.concatenate([w2v(word,_w2v_model,_w2v_dim) for word in words_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkAllInput(_data,_window_size,_w2v_model,_w2v_dim):\n",
    "    #labels = mkLabel()\n",
    "    inputs = mkInput(_data[\"sentences_list\"][_window_size],_w2v_model,_w2v_dim)\n",
    "    data_len = int(len(inputs) / len(_data[\"sentences_list\"][_window_size]))\n",
    "    return [inputs[i*data_len:(i+_window_size*2+1)*data_len] for i in range(len(_data[\"text_splited\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkLabel(_data):\n",
    "    labels = np.array([0 for i in range(len(_data[\"text_splited\"]))])\n",
    "    for i in _data[\"begin_sentence\"]:\n",
    "        labels[i] = 1\n",
    "    for i in _data[\"end_sentence\"]:\n",
    "        labels[i] = 2\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "\n",
    "class MLPNet (nn.Module):\n",
    "    def __init__(self, _input_len,_hidden_dim):\n",
    "        super(MLPNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(_input_len, _hidden_dim)\n",
    "        self.fc2 = nn.Linear(_hidden_dim, _hidden_dim)\n",
    "        self.fc3 = nn.Linear(_hidden_dim, num_classes)\n",
    "        self.dropout1 = nn.Dropout2d(0.2)\n",
    "        self.dropout2 = nn.Dropout2d(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        return F.relu(self.fc3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = {}\n",
    "for model_name in model_name_list:\n",
    "    [_, _lang, _window_size, _w2v_dim, _hidden_dim] = model_name.split(\"-\")\n",
    "    _window_size, _w2v_dim, _hidden_dim = int(_window_size), int(_w2v_dim), int(_hidden_dim)\n",
    "    model_list[model_name] = {\"lang\":_lang, \"window_size\":_window_size, \"w2v_dim\":_w2v_dim, \"hidden_dim\":_hidden_dim}\n",
    "    model_list[model_name][\"w2v_model\"] = word2vec.Word2Vec.load(model_name + \"/word2vec.gensim.model\")\n",
    "    _input_len = (_window_size * 2 + 1) * (_w2v_dim + len(pos_tag_dict) + 6)\n",
    "    model_list[model_name][\"input_len\"] = _input_len\n",
    "    model_list[model_name][\"net\"] = MLPNet(_input_len,_hidden_dim).to(device)\n",
    "    checkpoint = torch.load(sorted(glob.glob(model_name+\"/v*\"))[-1], map_location='cpu')#'cuda:0')\n",
    "    model_list[model_name][\"net\"].load_state_dict(checkpoint[\"model\"])\n",
    "    model_list[model_name][\"net\"].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def label_seq(data):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        data: dictionary of text, begin_sentences, end_sentences\n",
    "    Output:\n",
    "        a sequence of labels where each token from the text is assiciated with a label:\n",
    "            regular token --> O\n",
    "            begin sentences token --> BS\n",
    "            end sentences token --> ES\n",
    "    \"\"\"\n",
    "    text = data[\"text\"].split(\" \")\n",
    "    \n",
    "    True_Begin_sentences = data[\"begin_sentence\"]\n",
    "    True_End_sentences = data[\"end_sentence\"]\n",
    "    \n",
    "    labels_train = [\"O\"] * len(text)    \n",
    "    for index in True_Begin_sentences:\n",
    "        labels_train[index] =\"BS\"\n",
    "    for index in True_End_sentences:\n",
    "        labels_train[index] =\"ES\"\n",
    "    return labels_train\n",
    "\n",
    "\n",
    "def evaluate_result(data_true,data_pred):\n",
    "    \"\"\"\n",
    "    Report the score of Begin sentence and end sentences and regular labels\n",
    "    NB : Only F1 score of BS and ES will be taken under account in the evaluation (first two lines of the report)\n",
    "    data_true: a json file of the ground truth (rain_fr.json for instance)\n",
    "    data_pred is a json file in the same format as the json data files\n",
    "    \"\"\"\n",
    "    labels_true = label_seq(data_true)       \n",
    "    labels_pred = label_seq(data_pred)\n",
    "\n",
    "    \n",
    "    target_names= [\"O\",\"BS\",\"ES\"]\n",
    "    tag2idx = {t: i for i, t in enumerate(target_names)}\n",
    "    \n",
    "    y_true = [tag2idx[i] for i in labels_true]\n",
    "    y_pred = [tag2idx[i] for i in labels_pred]\n",
    "    return classification_report(y_true, y_pred, target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_name_list:\n",
    "    _lang = model_list[model_name][\"lang\"]\n",
    "    _window_size = model_list[model_name][\"window_size\"]\n",
    "    _w2v_dim = model_list[model_name][\"w2v_dim\"]\n",
    "    _hidden_dim = model_list[model_name][\"hidden_dim\"]\n",
    "    _w2v_model = model_list[model_name][\"w2v_model\"]\n",
    "    _net = model_list[model_name][\"net\"]\n",
    "    inputs_dev = mkAllInput(dev,_window_size,_w2v_model,_w2v_dim)\n",
    "    inputs_dev = torch.tensor(inputs_dev).float().to(device)\n",
    "    results_dev = _net(inputs_dev).argmax(1)\n",
    "    dev2 = {}\n",
    "    dev2[\"text\"] = dev[\"text\"]\n",
    "    dev2[\"begin_sentence\"] = []\n",
    "    dev2[\"end_sentence\"] = []\n",
    "    for i, _label in enumerate(results_dev):\n",
    "        if _label == 1:\n",
    "            dev2[\"begin_sentence\"].append(i)\n",
    "        elif _label == 2:\n",
    "            dev2[\"end_sentence\"].append(i)\n",
    "    model_list[model_name][\"macro_f1\"] = evaluate_result(dev,dev2).split(\"\\n\")[7].split(\" \")[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model-en-10-50-1200': {'lang': 'en',\n",
       "  'window_size': 10,\n",
       "  'w2v_dim': 50,\n",
       "  'hidden_dim': 1200,\n",
       "  'w2v_model': <gensim.models.word2vec.Word2Vec at 0x7fbdc5fb3cf8>,\n",
       "  'input_len': 2142,\n",
       "  'net': MLPNet(\n",
       "    (fc1): Linear(in_features=2142, out_features=1200, bias=True)\n",
       "    (fc2): Linear(in_features=1200, out_features=1200, bias=True)\n",
       "    (fc3): Linear(in_features=1200, out_features=3, bias=True)\n",
       "    (dropout1): Dropout2d(p=0.2)\n",
       "    (dropout2): Dropout2d(p=0.2)\n",
       "  ),\n",
       "  'macro_f1': '0.90'},\n",
       " 'model-en-20-50-1200': {'lang': 'en',\n",
       "  'window_size': 20,\n",
       "  'w2v_dim': 50,\n",
       "  'hidden_dim': 1200,\n",
       "  'w2v_model': <gensim.models.word2vec.Word2Vec at 0x7fbdbf920588>,\n",
       "  'input_len': 4182,\n",
       "  'net': MLPNet(\n",
       "    (fc1): Linear(in_features=4182, out_features=1200, bias=True)\n",
       "    (fc2): Linear(in_features=1200, out_features=1200, bias=True)\n",
       "    (fc3): Linear(in_features=1200, out_features=3, bias=True)\n",
       "    (dropout1): Dropout2d(p=0.2)\n",
       "    (dropout2): Dropout2d(p=0.2)\n",
       "  ),\n",
       "  'macro_f1': '0.90'},\n",
       " 'model-en-20-100-1200': {'lang': 'en',\n",
       "  'window_size': 20,\n",
       "  'w2v_dim': 100,\n",
       "  'hidden_dim': 1200,\n",
       "  'w2v_model': <gensim.models.word2vec.Word2Vec at 0x7fbdbf920860>,\n",
       "  'input_len': 6232,\n",
       "  'net': MLPNet(\n",
       "    (fc1): Linear(in_features=6232, out_features=1200, bias=True)\n",
       "    (fc2): Linear(in_features=1200, out_features=1200, bias=True)\n",
       "    (fc3): Linear(in_features=1200, out_features=3, bias=True)\n",
       "    (dropout1): Dropout2d(p=0.2)\n",
       "    (dropout2): Dropout2d(p=0.2)\n",
       "  ),\n",
       "  'macro_f1': '0.90'},\n",
       " 'model-en-10-100-600': {'lang': 'en',\n",
       "  'window_size': 10,\n",
       "  'w2v_dim': 100,\n",
       "  'hidden_dim': 600,\n",
       "  'w2v_model': <gensim.models.word2vec.Word2Vec at 0x7fbdbf8ed160>,\n",
       "  'input_len': 3192,\n",
       "  'net': MLPNet(\n",
       "    (fc1): Linear(in_features=3192, out_features=600, bias=True)\n",
       "    (fc2): Linear(in_features=600, out_features=600, bias=True)\n",
       "    (fc3): Linear(in_features=600, out_features=3, bias=True)\n",
       "    (dropout1): Dropout2d(p=0.2)\n",
       "    (dropout2): Dropout2d(p=0.2)\n",
       "  ),\n",
       "  'macro_f1': '0.91'},\n",
       " 'model-en-10-10-300': {'lang': 'en',\n",
       "  'window_size': 10,\n",
       "  'w2v_dim': 10,\n",
       "  'hidden_dim': 300,\n",
       "  'w2v_model': <gensim.models.word2vec.Word2Vec at 0x7fbda972e6a0>,\n",
       "  'input_len': 1302,\n",
       "  'net': MLPNet(\n",
       "    (fc1): Linear(in_features=1302, out_features=300, bias=True)\n",
       "    (fc2): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (fc3): Linear(in_features=300, out_features=3, bias=True)\n",
       "    (dropout1): Dropout2d(p=0.2)\n",
       "    (dropout2): Dropout2d(p=0.2)\n",
       "  ),\n",
       "  'macro_f1': '0.90'},\n",
       " 'model-en-5-50-300': {'lang': 'en',\n",
       "  'window_size': 5,\n",
       "  'w2v_dim': 50,\n",
       "  'hidden_dim': 300,\n",
       "  'w2v_model': <gensim.models.word2vec.Word2Vec at 0x7fbda9302ba8>,\n",
       "  'input_len': 1122,\n",
       "  'net': MLPNet(\n",
       "    (fc1): Linear(in_features=1122, out_features=300, bias=True)\n",
       "    (fc2): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (fc3): Linear(in_features=300, out_features=3, bias=True)\n",
       "    (dropout1): Dropout2d(p=0.2)\n",
       "    (dropout2): Dropout2d(p=0.2)\n",
       "  ),\n",
       "  'macro_f1': '0.90'},\n",
       " 'model-en-20-50-600': {'lang': 'en',\n",
       "  'window_size': 20,\n",
       "  'w2v_dim': 50,\n",
       "  'hidden_dim': 600,\n",
       "  'w2v_model': <gensim.models.word2vec.Word2Vec at 0x7fbda541f5c0>,\n",
       "  'input_len': 4182,\n",
       "  'net': MLPNet(\n",
       "    (fc1): Linear(in_features=4182, out_features=600, bias=True)\n",
       "    (fc2): Linear(in_features=600, out_features=600, bias=True)\n",
       "    (fc3): Linear(in_features=600, out_features=3, bias=True)\n",
       "    (dropout1): Dropout2d(p=0.2)\n",
       "    (dropout2): Dropout2d(p=0.2)\n",
       "  ),\n",
       "  'macro_f1': '0.90'},\n",
       " 'model-en-10-100-300': {'lang': 'en',\n",
       "  'window_size': 10,\n",
       "  'w2v_dim': 100,\n",
       "  'hidden_dim': 300,\n",
       "  'w2v_model': <gensim.models.word2vec.Word2Vec at 0x7fbda4e75c50>,\n",
       "  'input_len': 3192,\n",
       "  'net': MLPNet(\n",
       "    (fc1): Linear(in_features=3192, out_features=300, bias=True)\n",
       "    (fc2): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (fc3): Linear(in_features=300, out_features=3, bias=True)\n",
       "    (dropout1): Dropout2d(p=0.2)\n",
       "    (dropout2): Dropout2d(p=0.2)\n",
       "  ),\n",
       "  'macro_f1': '0.90'},\n",
       " 'model-en-5-10-600': {'lang': 'en',\n",
       "  'window_size': 5,\n",
       "  'w2v_dim': 10,\n",
       "  'hidden_dim': 600,\n",
       "  'w2v_model': <gensim.models.word2vec.Word2Vec at 0x7fbda4850518>,\n",
       "  'input_len': 682,\n",
       "  'net': MLPNet(\n",
       "    (fc1): Linear(in_features=682, out_features=600, bias=True)\n",
       "    (fc2): Linear(in_features=600, out_features=600, bias=True)\n",
       "    (fc3): Linear(in_features=600, out_features=3, bias=True)\n",
       "    (dropout1): Dropout2d(p=0.2)\n",
       "    (dropout2): Dropout2d(p=0.2)\n",
       "  ),\n",
       "  'macro_f1': '0.90'},\n",
       " 'model-en-20-10-300': {'lang': 'en',\n",
       "  'window_size': 20,\n",
       "  'w2v_dim': 10,\n",
       "  'hidden_dim': 300,\n",
       "  'w2v_model': <gensim.models.word2vec.Word2Vec at 0x7fbda42a4b70>,\n",
       "  'input_len': 2542,\n",
       "  'net': MLPNet(\n",
       "    (fc1): Linear(in_features=2542, out_features=300, bias=True)\n",
       "    (fc2): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (fc3): Linear(in_features=300, out_features=3, bias=True)\n",
       "    (dropout1): Dropout2d(p=0.2)\n",
       "    (dropout2): Dropout2d(p=0.2)\n",
       "  ),\n",
       "  'macro_f1': '0.88'},\n",
       " 'model-en-10-10-1200': {'lang': 'en',\n",
       "  'window_size': 10,\n",
       "  'w2v_dim': 10,\n",
       "  'hidden_dim': 1200,\n",
       "  'w2v_model': <gensim.models.word2vec.Word2Vec at 0x7fbda3e84400>,\n",
       "  'input_len': 1302,\n",
       "  'net': MLPNet(\n",
       "    (fc1): Linear(in_features=1302, out_features=1200, bias=True)\n",
       "    (fc2): Linear(in_features=1200, out_features=1200, bias=True)\n",
       "    (fc3): Linear(in_features=1200, out_features=3, bias=True)\n",
       "    (dropout1): Dropout2d(p=0.2)\n",
       "    (dropout2): Dropout2d(p=0.2)\n",
       "  ),\n",
       "  'macro_f1': '0.91'},\n",
       " 'model-en-20-10-1200': {'lang': 'en',\n",
       "  'window_size': 20,\n",
       "  'w2v_dim': 10,\n",
       "  'hidden_dim': 1200,\n",
       "  'w2v_model': <gensim.models.word2vec.Word2Vec at 0x7fbd9cf16a90>,\n",
       "  'input_len': 2542,\n",
       "  'net': MLPNet(\n",
       "    (fc1): Linear(in_features=2542, out_features=1200, bias=True)\n",
       "    (fc2): Linear(in_features=1200, out_features=1200, bias=True)\n",
       "    (fc3): Linear(in_features=1200, out_features=3, bias=True)\n",
       "    (dropout1): Dropout2d(p=0.2)\n",
       "    (dropout2): Dropout2d(p=0.2)\n",
       "  ),\n",
       "  'macro_f1': '0.90'},\n",
       " 'model-en-20-50-300': {'lang': 'en',\n",
       "  'window_size': 20,\n",
       "  'w2v_dim': 50,\n",
       "  'hidden_dim': 300,\n",
       "  'w2v_model': <gensim.models.word2vec.Word2Vec at 0x7fbd9c772320>,\n",
       "  'input_len': 4182,\n",
       "  'net': MLPNet(\n",
       "    (fc1): Linear(in_features=4182, out_features=300, bias=True)\n",
       "    (fc2): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (fc3): Linear(in_features=300, out_features=3, bias=True)\n",
       "    (dropout1): Dropout2d(p=0.2)\n",
       "    (dropout2): Dropout2d(p=0.2)\n",
       "  ),\n",
       "  'macro_f1': '0.89'},\n",
       " 'model-en-5-10-1200': {'lang': 'en',\n",
       "  'window_size': 5,\n",
       "  'w2v_dim': 10,\n",
       "  'hidden_dim': 1200,\n",
       "  'w2v_model': <gensim.models.word2vec.Word2Vec at 0x7fbd9b7496d8>,\n",
       "  'input_len': 682,\n",
       "  'net': MLPNet(\n",
       "    (fc1): Linear(in_features=682, out_features=1200, bias=True)\n",
       "    (fc2): Linear(in_features=1200, out_features=1200, bias=True)\n",
       "    (fc3): Linear(in_features=1200, out_features=3, bias=True)\n",
       "    (dropout1): Dropout2d(p=0.2)\n",
       "    (dropout2): Dropout2d(p=0.2)\n",
       "  ),\n",
       "  'macro_f1': '0.91'},\n",
       " 'model-en-20-100-300': {'lang': 'en',\n",
       "  'window_size': 20,\n",
       "  'w2v_dim': 100,\n",
       "  'hidden_dim': 300,\n",
       "  'w2v_model': <gensim.models.word2vec.Word2Vec at 0x7fbd9cfe0278>,\n",
       "  'input_len': 6232,\n",
       "  'net': MLPNet(\n",
       "    (fc1): Linear(in_features=6232, out_features=300, bias=True)\n",
       "    (fc2): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (fc3): Linear(in_features=300, out_features=3, bias=True)\n",
       "    (dropout1): Dropout2d(p=0.2)\n",
       "    (dropout2): Dropout2d(p=0.2)\n",
       "  ),\n",
       "  'macro_f1': '0.89'},\n",
       " 'model-en-5-100-1200': {'lang': 'en',\n",
       "  'window_size': 5,\n",
       "  'w2v_dim': 100,\n",
       "  'hidden_dim': 1200,\n",
       "  'w2v_model': <gensim.models.word2vec.Word2Vec at 0x7fbd989d0e48>,\n",
       "  'input_len': 1672,\n",
       "  'net': MLPNet(\n",
       "    (fc1): Linear(in_features=1672, out_features=1200, bias=True)\n",
       "    (fc2): Linear(in_features=1200, out_features=1200, bias=True)\n",
       "    (fc3): Linear(in_features=1200, out_features=3, bias=True)\n",
       "    (dropout1): Dropout2d(p=0.2)\n",
       "    (dropout2): Dropout2d(p=0.2)\n",
       "  ),\n",
       "  'macro_f1': '0.90'},\n",
       " 'model-en-10-50-600': {'lang': 'en',\n",
       "  'window_size': 10,\n",
       "  'w2v_dim': 50,\n",
       "  'hidden_dim': 600,\n",
       "  'w2v_model': <gensim.models.word2vec.Word2Vec at 0x7fbd9b8c2198>,\n",
       "  'input_len': 2142,\n",
       "  'net': MLPNet(\n",
       "    (fc1): Linear(in_features=2142, out_features=600, bias=True)\n",
       "    (fc2): Linear(in_features=600, out_features=600, bias=True)\n",
       "    (fc3): Linear(in_features=600, out_features=3, bias=True)\n",
       "    (dropout1): Dropout2d(p=0.2)\n",
       "    (dropout2): Dropout2d(p=0.2)\n",
       "  ),\n",
       "  'macro_f1': '0.84'},\n",
       " 'model-en-5-100-300': {'lang': 'en',\n",
       "  'window_size': 5,\n",
       "  'w2v_dim': 100,\n",
       "  'hidden_dim': 300,\n",
       "  'w2v_model': <gensim.models.word2vec.Word2Vec at 0x7fbd96c7ee80>,\n",
       "  'input_len': 1672,\n",
       "  'net': MLPNet(\n",
       "    (fc1): Linear(in_features=1672, out_features=300, bias=True)\n",
       "    (fc2): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (fc3): Linear(in_features=300, out_features=3, bias=True)\n",
       "    (dropout1): Dropout2d(p=0.2)\n",
       "    (dropout2): Dropout2d(p=0.2)\n",
       "  ),\n",
       "  'macro_f1': '0.89'},\n",
       " 'model-en-10-50-300': {'lang': 'en',\n",
       "  'window_size': 10,\n",
       "  'w2v_dim': 50,\n",
       "  'hidden_dim': 300,\n",
       "  'w2v_model': <gensim.models.word2vec.Word2Vec at 0x7fbd9a1320b8>,\n",
       "  'input_len': 2142,\n",
       "  'net': MLPNet(\n",
       "    (fc1): Linear(in_features=2142, out_features=300, bias=True)\n",
       "    (fc2): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (fc3): Linear(in_features=300, out_features=3, bias=True)\n",
       "    (dropout1): Dropout2d(p=0.2)\n",
       "    (dropout2): Dropout2d(p=0.2)\n",
       "  ),\n",
       "  'macro_f1': '0.90'},\n",
       " 'model-en-5-100-600': {'lang': 'en',\n",
       "  'window_size': 5,\n",
       "  'w2v_dim': 100,\n",
       "  'hidden_dim': 600,\n",
       "  'w2v_model': <gensim.models.word2vec.Word2Vec at 0x7fbd96059438>,\n",
       "  'input_len': 1672,\n",
       "  'net': MLPNet(\n",
       "    (fc1): Linear(in_features=1672, out_features=600, bias=True)\n",
       "    (fc2): Linear(in_features=600, out_features=600, bias=True)\n",
       "    (fc3): Linear(in_features=600, out_features=3, bias=True)\n",
       "    (dropout1): Dropout2d(p=0.2)\n",
       "    (dropout2): Dropout2d(p=0.2)\n",
       "  ),\n",
       "  'macro_f1': '0.90'},\n",
       " 'model-en-5-50-1200': {'lang': 'en',\n",
       "  'window_size': 5,\n",
       "  'w2v_dim': 50,\n",
       "  'hidden_dim': 1200,\n",
       "  'w2v_model': <gensim.models.word2vec.Word2Vec at 0x7fbd95aafcf8>,\n",
       "  'input_len': 1122,\n",
       "  'net': MLPNet(\n",
       "    (fc1): Linear(in_features=1122, out_features=1200, bias=True)\n",
       "    (fc2): Linear(in_features=1200, out_features=1200, bias=True)\n",
       "    (fc3): Linear(in_features=1200, out_features=3, bias=True)\n",
       "    (dropout1): Dropout2d(p=0.2)\n",
       "    (dropout2): Dropout2d(p=0.2)\n",
       "  ),\n",
       "  'macro_f1': '0.90'},\n",
       " 'model-en-5-50-600': {'lang': 'en',\n",
       "  'window_size': 5,\n",
       "  'w2v_dim': 50,\n",
       "  'hidden_dim': 600,\n",
       "  'w2v_model': <gensim.models.word2vec.Word2Vec at 0x7fbd952894a8>,\n",
       "  'input_len': 1122,\n",
       "  'net': MLPNet(\n",
       "    (fc1): Linear(in_features=1122, out_features=600, bias=True)\n",
       "    (fc2): Linear(in_features=600, out_features=600, bias=True)\n",
       "    (fc3): Linear(in_features=600, out_features=3, bias=True)\n",
       "    (dropout1): Dropout2d(p=0.2)\n",
       "    (dropout2): Dropout2d(p=0.2)\n",
       "  ),\n",
       "  'macro_f1': '0.91'},\n",
       " 'model-en-20-10-600': {'lang': 'en',\n",
       "  'window_size': 20,\n",
       "  'w2v_dim': 10,\n",
       "  'hidden_dim': 600,\n",
       "  'w2v_model': <gensim.models.word2vec.Word2Vec at 0x7fbd94addda0>,\n",
       "  'input_len': 2542,\n",
       "  'net': MLPNet(\n",
       "    (fc1): Linear(in_features=2542, out_features=600, bias=True)\n",
       "    (fc2): Linear(in_features=600, out_features=600, bias=True)\n",
       "    (fc3): Linear(in_features=600, out_features=3, bias=True)\n",
       "    (dropout1): Dropout2d(p=0.2)\n",
       "    (dropout2): Dropout2d(p=0.2)\n",
       "  ),\n",
       "  'macro_f1': '0.90'},\n",
       " 'model-en-10-10-600': {'lang': 'en',\n",
       "  'window_size': 10,\n",
       "  'w2v_dim': 10,\n",
       "  'hidden_dim': 600,\n",
       "  'w2v_model': <gensim.models.word2vec.Word2Vec at 0x7fbd93b39550>,\n",
       "  'input_len': 1302,\n",
       "  'net': MLPNet(\n",
       "    (fc1): Linear(in_features=1302, out_features=600, bias=True)\n",
       "    (fc2): Linear(in_features=600, out_features=600, bias=True)\n",
       "    (fc3): Linear(in_features=600, out_features=3, bias=True)\n",
       "    (dropout1): Dropout2d(p=0.2)\n",
       "    (dropout2): Dropout2d(p=0.2)\n",
       "  ),\n",
       "  'macro_f1': '0.90'},\n",
       " 'model-en-10-100-1200': {'lang': 'en',\n",
       "  'window_size': 10,\n",
       "  'w2v_dim': 100,\n",
       "  'hidden_dim': 1200,\n",
       "  'w2v_model': <gensim.models.word2vec.Word2Vec at 0x7fbd9330ecc0>,\n",
       "  'input_len': 3192,\n",
       "  'net': MLPNet(\n",
       "    (fc1): Linear(in_features=3192, out_features=1200, bias=True)\n",
       "    (fc2): Linear(in_features=1200, out_features=1200, bias=True)\n",
       "    (fc3): Linear(in_features=1200, out_features=3, bias=True)\n",
       "    (dropout1): Dropout2d(p=0.2)\n",
       "    (dropout2): Dropout2d(p=0.2)\n",
       "  ),\n",
       "  'macro_f1': '0.90'},\n",
       " 'model-en-20-100-600': {'lang': 'en',\n",
       "  'window_size': 20,\n",
       "  'w2v_dim': 100,\n",
       "  'hidden_dim': 600,\n",
       "  'w2v_model': <gensim.models.word2vec.Word2Vec at 0x7fbd92769470>,\n",
       "  'input_len': 6232,\n",
       "  'net': MLPNet(\n",
       "    (fc1): Linear(in_features=6232, out_features=600, bias=True)\n",
       "    (fc2): Linear(in_features=600, out_features=600, bias=True)\n",
       "    (fc3): Linear(in_features=600, out_features=3, bias=True)\n",
       "    (dropout1): Dropout2d(p=0.2)\n",
       "    (dropout2): Dropout2d(p=0.2)\n",
       "  ),\n",
       "  'macro_f1': '0.90'},\n",
       " 'model-en-5-10-300': {'lang': 'en',\n",
       "  'window_size': 5,\n",
       "  'w2v_dim': 10,\n",
       "  'hidden_dim': 300,\n",
       "  'w2v_model': <gensim.models.word2vec.Word2Vec at 0x7fbd91dbea58>,\n",
       "  'input_len': 682,\n",
       "  'net': MLPNet(\n",
       "    (fc1): Linear(in_features=682, out_features=300, bias=True)\n",
       "    (fc2): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (fc3): Linear(in_features=300, out_features=3, bias=True)\n",
       "    (dropout1): Dropout2d(p=0.2)\n",
       "    (dropout2): Dropout2d(p=0.2)\n",
       "  ),\n",
       "  'macro_f1': '0.90'}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_name_list:\n",
    "    _lang = model_list[model_name][\"lang\"]\n",
    "    _window_size = model_list[model_name][\"window_size\"]\n",
    "    _w2v_dim = model_list[model_name][\"w2v_dim\"]\n",
    "    _hidden_dim = model_list[model_name][\"hidden_dim\"]\n",
    "    _w2v_model = model_list[model_name][\"w2v_model\"]\n",
    "    _net = model_list[model_name][\"net\"]\n",
    "    inputs_dev = mkAllInput(test,_window_size,_w2v_model,_w2v_dim)\n",
    "    inputs_dev = torch.tensor(inputs_dev).float().to(device)\n",
    "    results_dev = _net(inputs_dev).argmax(1)\n",
    "    test2 = {}\n",
    "    test2[\"text\"] = test[\"text\"]\n",
    "    test2[\"begin_sentence\"] = []\n",
    "    test2[\"end_sentence\"] = []\n",
    "    for i, _label in enumerate(results_dev):\n",
    "        if _label == 1:\n",
    "            test2[\"begin_sentence\"].append(i)\n",
    "        elif _label == 2:\n",
    "            test2[\"end_sentence\"].append(i)\n",
    "    model_list[model_name][\"test_begin_sentence\"] = test2[\"begin_sentence\"]\n",
    "    model_list[model_name][\"test_end_sentence\"] = test2[\"end_sentence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = {}\n",
    "final[\"text\"] = test[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_agree = {}\n",
    "vote_agree[\"begin_sentence\"] = {}\n",
    "vote_agree[\"end_sentence\"] = {}\n",
    "for model_name in model_name_list:\n",
    "    for i in model_list[model_name][\"test_begin_sentence\"]:\n",
    "        if i not in vote_agree[\"begin_sentence\"]:\n",
    "            vote_agree[\"begin_sentence\"][i] = 1\n",
    "        else:\n",
    "            vote_agree[\"begin_sentence\"][i] += 1\n",
    "    for i in model_list[model_name][\"test_end_sentence\"]:\n",
    "        if i not in vote_agree[\"end_sentence\"]:\n",
    "            vote_agree[\"end_sentence\"][i] = 1\n",
    "        else:\n",
    "            vote_agree[\"end_sentence\"][i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = len(model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.82"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thr = model_num * 0.66\n",
    "thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final[\"begin_sentence\"] = []\n",
    "final[\"end_sentence\"] = []\n",
    "for i,votes in vote_agree[\"begin_sentence\"].items():\n",
    "    if votes >=thr:\n",
    "        final[\"begin_sentence\"].append(i)\n",
    "for i,votes in vote_agree[\"end_sentence\"].items():\n",
    "    if votes >=thr:\n",
    "        final[\"end_sentence\"].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       1.00      0.99      0.99     47091\n",
      "          BS       0.81      0.87      0.84      1384\n",
      "          ES       0.87      0.98      0.92      1384\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     49859\n",
      "   macro avg       0.89      0.95      0.92     49859\n",
      "weighted avg       0.99      0.99      0.99     49859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evalfun.evaluate_result(test,final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
